# 哈希表



### 0x00 基本定义



**Definition** 数组可以被称为==直接寻址表==（direct-address table）， 因为我们需要访问数组中的某个元素的时候，直接使用其对应的数组下标即可.  即具有关键字为$k$的元素放在数组的$k$槽里面. 



**Definition** 若关键字$k$的元素放在数组的$h(k)$糟中，其中$h(x)$表示一个hash function，此时的数组我们称为==哈希表==.  称$h(k)$为关键字$k$的hash value. 



### 0x01 解决冲突

由于$h(x)$可能不是具有单值性，因此存在$h(k_1) = h(k_2)$，那么其hashtable上$h(k_1)$对应的凹槽处就需要存放两个元素，为了解决这个冲突，存在两种方法

1. ==链接法== 每个凹槽处我们用一种链表来表示，即可以记录多个hash-value相同的关键字。 
2. ==开放寻址法== 将所有元素都放在哈希表里面，当出现冲突的时候，我们使用的一种系统的方法去二次查询。



**Definition** 对于一个能存放$n$个元素，具有$m$个槽位的hashtable $T$，定义$T$的==装载因子==$\alpha$为$\frac{n}{m}$，即从链接法解决冲突时，其中一个链的平均长度.  

**Definition** 假定任意给定一个元素都会等可能的落到$m$个槽中的任意一个，且与其他元素被散列到什么位置上无关，称这个假设为==简单均匀散列==（simple uniform hashing）. 



**Lemma** 在简单均匀散列的假设下，给定$n$个元素，落在第$j$个凹槽上的期望为$E(k=j) = \frac{n}{m}$.

*proof*. 可以想成一个二项分布$B(\frac1m,n)$，其中表示每个元素落在第$j$个凹槽上的概率. 自然它的期望就是$\frac nm$. 



**Proposition** 在简单均匀散列的假设下，对应用链表法解决冲突的hashtable，一次不成功查找的平均时间为$O(1+\alpha)$. 

*proof*. 其中$O(1)$表示计算一次hash-value所需要的时间和直接对hashtable寻址的时间，不成功查找的前提下，我们需要对某条单链进行完全的遍历，因此需要$O(\alpha)$时间. 



**Proposition** 在简单均匀散列的假设下，对应用链表法解决冲突的hashtable，一次成功查找的平均时间为$O(1+\alpha)$. 

*proof*.  分析这个问题的关键在于，需要准确的刻画你需要查找的那个元素$x$在链表的哪个位置.  即需要算出$x$前面元素个数期望.



**关于开放寻找法的细节**

如何构造一个用于开放寻址法简单的散列表？

1. 若要插入关键字$k$，首先计算$h(k)$的值;
2. 在$T$上定位到$h(k)$的位置，若$h(k)$处为$NIL$，那么就将$k$插入到该位置;
3. 若$h(k)$处已经存在某个关键字，那么继续在$T$上从$h(k)$的位置向下连续地寻找，直到找到一个空的凹槽;
4. 若当遍历完成整个表的时候，还是找不到凹槽说明当前散列表已经满了. 

上述的整个过程被称为一个探查（probe）的过程.  查找关键字$k$的探查算法同理，但是终止条件多了一个，就是碰到空的凹槽可以直接终止。



一般的探查过程的分析性质:

1. 探查过程不一定需要是连续的，但是其探查顺序一定对应于$<0,1,\cdots,m-1>$的一个全排列，这个序列称为==探查序列==（从0开始）.  注意理解这里的序列，如果是$<2,1,3,\cdots>$这样一个序列，表示的是$T[0]$在探查顺序中处于第2位，$T[1]$ 表示在探查顺序中处于第1位，余类推. 
2. 若每个关键字的探查序列等可能的为$<0,1,\cdots,m-1>$的全排列中的任意一种，这个假设称为均匀散列. 



**推广hash-function** 经过上述的分析，每一个关键字对应了一个探查序列，我们将构造探查序列的过程也加入到hash-function中，此时hash-function我们定义为
$$
h: U\times \{0,1,\cdots,m-1\} \to  \{1,\cdots,m\}
$$
其中$h$接受两个参数，一个是关键字$k$，一个是散列表$T$的下标.   例如$h(k,0)$，就表示$T[0]$在寻找$k$的过程中是处于第$h(k,0)$位被探查的，由此我们可以给出一个探查$k$的一个探测的序列
$$
<h(k,0),h(k,1),\cdots,h(k,m-1)>
$$


常见构造探查序列的方法：

1. 线性查找 给定一个辅助散列函数$h'(x)$，此时散列函数定义为
   $$
   h(k,i) = (h'(k)+i)~ \text{mod}~ m , i =0 ,1,\cdots m-1.
   $$
   这个过程就相当于一个大圆盘，寻找一个位置顺时针或者逆时针转，初始位置$h'(k)$决定了整个序列.  故最多只能产生$m$个探查序列

2. 二次探查  给定一个辅助散列函数$h'(x)$，此时散列函数定义为
   $$
   h(k,i) = (h'(k) + c_1i +c_2i^2) ~\text{mod}~ m
   $$
   其中$c_1,c_2$均为常数，还是以初始位置$h'(k)$决定探查顺序，因此这种方式最多也只能产生$m$个探查序列。

3.  双重散列 给定两个辅助散列函数$h_1(k),h_2(k)$，此时的散列函数定义为
   $$
   h(k,i) = (h_1(k)+ih_2(k))~\text{mod}~m
   $$
   此时需要$h_1(k) = h_1(l)~\text{and}~h_2(k) = h_2(l)$，不同两个关键字的探查序列才相同，因此这种方式最多可以产生$m^2$个探查序列。 这里为了遍历整个T，$h_2(k)$必须和$m$是互素的，这里比较简洁的取法就是取$m$是素数，或者$m=2^k$且$h_2(k)$总是奇数.



常见构造探查序列的方法的一些不足

1. 线性探查中如果连续被占用的凹槽越大来越多的，那么查找一个空槽的概率也会越来长。   
2. 线性探查和二次探查一样，如果$h'(k)$相同其探查序列就是一样的。



**Proposition** 给定一个装置因子为$\alpha = n/m < 1$的开放寻址散列表，并假设是均匀散列的，则对于一次不成功的查找，其期望的探查次数至多为$1/(1-\alpha)$.  



**Proposition** 给定一个装置因子为$\alpha = n/m < 1$的开放寻址散列表，并假设是均匀散列的，则对于一次成功的查找，其期望的探查次数至多为$\frac{1}{a} \ln \frac{1}{1-\alpha}$.



### 0x02 散列函数

对于一个散列函数的思考:

1. ==一个好的散列函数应该近似满足简单均匀假设==. 
2. 一个散列函数应该具备接受的输入不仅仅是数字，当接受一个字符串时应能将其转换为数字. 



常见的散列函数的设计

1. 除法散列 $h(k) = k~ \text{mod} ~m$，其中$m$表示散列表的长度.  一个不接近$2$的整数幂的素数通常是一个好的除数$m$选择. 

2. 乘法散列 $h(k) = \lfloor m(kA ~\text{mod}~ 1) \rfloor$，其中$0 < A < 1$.  一般的取$m$为某个$2^k$.  

   若某计算机的字长为$\omega$，我们取$A = \frac{s}{2^\omega}$，其中$0< s < 2^\omega$且$s$是一个自然数.  那么$Ak \cdot 2^\omega$就是一个2个字长的自然数，可以用$r_12^\omega+r_0$表示，其中$r_1$表示它的前面这个乘积的高位字，而$r_0$表示乘积的低位字.  设$m=2^p$也是一个字长的自然数，显然$r_0$的高$p$位就是所求的hashvalue.  这是为什么呢？ 

   显然$A$是可以用一个字长来表示的，即$A = i_12^{-1} + i_22^{-2} + \cdots + i_\omega2^{-\omega}$，其中$i_1,i_2,\cdots,i_\omega \in \{0,1\}$.  对于$k$我们也用$k = j_12^{1} + j_22^{2} + \cdots + j_\omega2^{\omega}$表示，因此
   $$
   Ak\cdot 2^{\omega} = (i_12^{-1} + i_22^{-2} + \cdots + i_\omega2^{-\omega})(j_12^{1} + j_22^{2} + \cdots + j_\omega2^{\omega})2^{\omega}
   $$
   实际上就是把$Ak$的小数搬到了$r_0$上，再乘上$m=2^p$再取整，就是取了$r_0$的高$p$的那串数字. 

3. 全域散列 如果给定一组有限散列函数$\mathsf{H}$，对任意给定的两个不同的关键字$k,l$，使得满足$h(k)=h(l)$的散列函数$h \in \mathsf{H}$的个数最多为$|\mathsf{H}|/m$，其中$m$为散列表的长度. 这样的函数组$\mathsf{H}$就称为是全域的（universal）.  换句话说就是从$\mathsf{H}$任意选择一个散列函数，$h(k) = h(l)$等于的概率不超过$1/m$.   使用这种函数组构造散列表的方法被称为全域散列。

   如何设计全域散列函数？



### 0xFF 考点

**Problem** 对大规模数组实现非初始化的直接寻址.  (例如有一个数组但是这个数组上面已经存在一些无用的信息，你如果想将其拿过来直接用且不经过初始化，当你访问数组的某个位置的元素时，怎么保证它是我们之前插入的元素还是它原本存在的一些无用信息，这就是解决问题的关键所在)

这里关注三种操作search，insert，delete.  我们额外提供一个栈结构，它的深度是和实际存储在大数组里面元素个数成正比.  

```python
insert(A,S,x)
	push(S, x) 
    A[x.key] = S.top # 存储指向当且栈顶元素的指针
    
search(A, S, k)
	if A[k] in S
    	if A[k].ele.key == k #其中A[k].ele为x，即x作为栈元素一个属性
        	return A[x.key].ele
    return NIL

delete(A,S,x)
	A[x.k].ele = S.top.ele #用栈顶元素替换删除x之后产生的空洞. 
    A[x.k] = NIL
    pop(S)
```

------

**Problem** 假设一个散列函数$h$将$n$个关键字均匀散列到一个长度为$m$的数组$T$中，集合$\{(k,l): k \neq l ~\text{and}~ h(k)=h(l)\}$的期望基数为$C_n^2 \cdot \frac1m$ 

------

**Problem** 若考虑将链接法解决冲突情况下的链表都排好序对性能有什么影响?

- 对一次成功查找，几乎没有影响. 
- 对一次不成功的查找，可以通过范围来判断元素是否存在，例如链表是递增排序的，若需要查询的关键字小于首元素的关键字，那么可以直接判断查找成功.
- 对一次插入，降低了插入的性能，因为需要遍历链表来确定合适位置插入.
- 对一次删除，没有影响. 

------

**Problem** 若将$n$个关键字的集合存储到一个大小为$m$的散列表中（用连接法解决冲突），其中关键子的全域为$U$，且$|U| > nm$.  证明$U$存在一个大小为$n$的子集使得其中所有的关键字都被散列到一个slot上. 

*proof.* 假设不存在这样的子集，即若将$U$起来的关键字都散列到哈希表上，每个槽上的关键字个数最多为$n-1$.  那么这种情况下哈希表上一共有$(n-1)m$个元素这是小于$|U|$，这和命题条件是矛盾的，因此存在这样大小为$n$的子集. 

------

**Problem** 若将$n$个关键字的集合存储到一个大小为$m$的散列表中（用连接法解决冲突）， 同时已知每个链的长度，包括其中最长链的长度$L$.  描述如何从该散列表的所有关键字中均匀随机地选择某一个元素并在$O(L\cdot(1+1/\alpha))$的期望时间内返回该关键字的过程.

设每条链的长度为$n_i$，这个过程为

1. 随机地从$1-m$中选择一个散列表的slot  $T[i]$.  
2. 随机地从$1-L$选择一个数$j$作为从$T[i]$指向的链表中取出的第几个元素. 
3. 如果$j \leq n_i$，则可以返回对应的元素. 反之如果$j > n_i$，我们回到操作1重复前述操作.

显然这是一个均匀随机选择关键字返回的过程.  我们可以把整张哈希表$T$想象成一个二维的数组，大小为$Lm$，其中有$n$个位置存有元素. 从$T$中随机地取一个位置的元素，可以取到概率为$n/Lm$.  此时我们需要考虑正好取到一个元素的期望次数， 我们可以将其想象成一个二项分布$B(n/Lm,k)$，其中$k$为取的次数，它的期望为$nk/Lm$，当$nk/Lm = 1$时，我们可以得到$k = Lm/n$.  因此正好取到一个元素的期望次数为$Lm/n$. 当正好取到一个元素之后我们需要根据$j$遍历对应的slot，这个时间为$O(L)$，每次选择一个元素的需要时间为$O(1)$.  那么期望返回时间为
$$
L \cdot m/n \cdot O(1) + O(L) = O(L(1+1/\alpha))
$$
其中$\alpha = n/m$. 



















